## KubeDoor 1.0 全新架构，全新的灵活部署方案
![KubeDoor1 0 0 drawio](../screenshot/1.0/kubedoor1.0-arch.png)
<div align="center">
<img src="../screenshot/1.0/vm-arch.png" width="650;" />
</div>

### 组件说明
#### master端(安装在kubedoor命名空间)
- kubedoor-master: 对接agent，提供api接口
- kubedoor-web: 前端界面，整合nginx
- kubedoor-dash: Grafana
- kubedoor-alarm: 接收alertmanager的告警，执行通知与入库
- kubedoor-collect: 定时任务，调用api采集高峰期资源
#### 基础设施(默认和master端部署在一起)
- alertmanager: 告警路由服务
- vmalert: 告警规则计算与管理，触发告警后通知到alertmanager
- VictoriaMetrics: 时序数据库
- ClickHouse:列式数据库
#### agent端(安装在kubedoor命名空间)
- kubedoor-agent: 对接master，调用K8S API
- vmagent: 替代Prometheus，采集监控指标
- KubeStateMetrics: 获取K8S的指标
- NodeExporter: 获取主机的指标

## 部署方案
### 0. 下载并进入目录
```
### 【下载helm包】
wget https://StarsL.cn/kubedoor/kubedoor-1.0.0.tgz
tar -zxvf kubedoor-1.0.0.tgz
cd kubedoor
```
### 1. 全新部署（您的K8S没有部署监控系统）
- **master部署:**
1. 配置文件修改: `values-master.yaml`
    1. **`storageClass`**：【特别注意】默认的部署方案会把`ClickHouse`(单机版)和`VictoriaMetrics`(单机版)都部署在K8S（kubedoor命名空间）内，这2个服务需要存储，注意要填写正确您K8S的`storageClass`（注意有2处`storageClass`）。
    2. **`CK_PASSWORD`**：【可保持默认】自动部署`ClickHouse`时会将这个密码设置为default用户的密码。
    3. **`external_labels_key`**：【可保持默认】这是用于多K8S监控数据，通过远程写方式，写入到同一个时序数据库的场景。使用远程存储时，这个key/value会作为标签增加到每一个指标中，这样通过这个标签就可以区分出指标属于哪个K8S了。注意agent端的`external_labels_key`要和master端的`external_labels_key`保持一致。如果是新安装`VictoriaMetrics`可以使用默认配置的`origin_prometheus`不变。
    4. **`vm_single`**：【可保持默认】自动部署`Victoria-Metrics-Single`时需要配置的账号密码，存储时长等信息。
    5. **`nginx_auth`**：【可保持默认】这个是web登录的账号密码信息，是使用的nginx basic认证，默认设置了2个用户，一个用于web登录，一个用于agent与master通讯使用，可以根据需要修改。
    6. **`MSG_TYPE/MSG_TOKEN`**：【需要修改】master端的通知IM类型和机器人token，主要用于告警的默认通知的群机器人，你也可以在alertmanager配置更详细的通知路由。

2. 完成配置修改后执行检查与安装：
```
# try
helm install kubedoor . --namespace kubedoor --create-namespace --values values-master.yaml --dry-run --debug
# install
helm install kubedoor . --namespace kubedoor --create-namespace --values values-master.yaml
```
3. 访问WebUI：使用K8S节点IP + kubedoor-web的NodePort访问，默认账号密码都是 **`kubedoor`**
4. 告警逻辑说明：`vmalert`从`VictoriaMetrics`读取数据，并进行规则比较后，如果触发了告警就会通知到`alertmanager`，alertmanager收到告警后会路由到`kubedoor-alarm`进行告警通知和入库。即使您的K8S内已经有`alertmanager`也不用担心，KubeDoor的alertmanager会安装在kubedoor命名空间，不会冲突。
- **agent部署:**
1. 配置文件修改: `values-agent.yaml`
    1. **`ws`**：agent和master是同一个K8S：配置为`ws://kubedoor-master.kubedoor`即可，免认证。如果是跨K8S的情况，请配置为您的kubedoor-web外部可访问的地址端口，并按照例子配置认证信息。
    2. **`MSG_TYPE/MSG_TOKEN`**：大部分对该K8S的操作会通过该机器人进行通知。（不同的K8S可以配置不同的群机器人）
    3. **`OSS_URL`**：java服务执行dump、jfr、jstack时会把数据存放到OSS，请填写您的OSS地址。（注意设置允许内网免认证上传）
    4. **`external_labels_key`**：注意部署到多套K8S时，请保持external_labels_key都相同，并且与kubedoor-master的也相同。
    5. **`external_labels_value`**：设置为您的K8S的名称。
    6. **`remoteWriteUrl`**：这是vmagent远程写时序数据库的完整URL。agent和master是同一个K8S：配置为`http://monit:dduF1E3sj@victoria-metrics.kubedoor:8428/api/v1/write`，如果是跨K8S的情况，注意修改`victoria-metrics.kubedoor:8428`为您的Victoria-Metrics外部可访问的地址端口。注意账号密码是mater配置中的`vm_single`的账号密码。
    7. **`kube_state_metrics`**：如果您开启了`vmagent`安装，请确保`kube_state_metrics`也是开启的，`vmagent`需要采集kubedoor的`kube_state_metrics`的指标，`kube_state_metrics`会部署在kubedoor命名空间内，不会与您已有的`kube_state_metrics`冲突。
    8. **`node_exporter`**：如果您的K8S节点已部署node-exporter，请设置为false，否则会冲突。

2. 完成配置修改后执行检查与安装：
```
# try
helm install kubedoor . --namespace kubedoor --create-namespace --values values-agent.yaml --dry-run --debug
# install
helm install kubedoor . --namespace kubedoor --create-namespace --values values-agent.yaml
```
3. 访问KubeDoor-Web，点击`agent管理`，找到您部署agent的K8S名称，状态应该是`在线`，先开启自动采集，设置好高峰期时段，再执行采集：输入需要采集的历史数据时长，点击采集，即可采集历史数据并更新高峰时段数据到管控表。
4. 在其它的K8S部署agent。
   ```
   helm install kubedoor-agent . --namespace kubedoor --create-namespace --values values-agent.yaml --set tsdb.external_labels_value=xxxxxx
   ```

### 2. 独立部署ClickHouse与VictoriaMetrics
- `ClickHouse`可以使用`docker compose`在主机上部署。
```
# 默认使用docker compose运行，部署在/opt/clickhouse目录下。
curl -s https://StarsL.cn/kubedoor/install-clickhouse.sh|sudo bash
# 启动ClickHouse（启动后会自动初始化表结构）
cd /opt/clickhouse && docker compose up -d
```
- `VictoriaMetrics`可以使用`docker compose`在主机上部署。
```
mkdir -p /opt/victoriametrics/data
wget https://StarsL.cn/kubedoor/victoriametrics-docker-compose.yaml -o /opt/victoriametrics/docker-compose.yaml
cd /opt/victoriametrics/
docker compose up -d
```
### 3. 接入部署（已经有完整的多K8S监控系统）
>前提1：每个K8S内已经部署Prometheus/vmagent，采集的数据统一远程写到**`VictoriaMetrics`**
>前提2：已经部署好的ClickHouse
- **master部署:**
1. 配置文件修改: `values-master.yaml`
   1. **`clickhouse.enable`**：设置为`false`
   2. **`CK_PASSWORD/CK_HOST/CK_PORT/CK_HTTP_PORT/CK_USER`**：根据您已有的ClickHouse信息填写
   3. **`tsdb.type`**：根据您已有的时序数据库填写`Victoria-Metrics-Single`或`Victoria-Metrics-Cluster`
   4. **`external_labels_key`**：**注意填写您已经在`Prometheus/vmagent`中配置的`external_labels`的key，如果您没有配置过请在您的`Prometheus/vmagent`中新增一个。**
   5. **`url/remoteRead/remoteWrite`**：单机版配置url即可，集群版需要配置remoteRead/remoteWrite，请按照示例规范填写。
   6. **`MSG_TYPE/MSG_TOKEN`**：master端的通知IM类型和机器人token，主要用于告警的默认通知的群机器人，你也可以在alertmanager配置更详细的通知路由。
2. 完成配置修改后执行检查与安装：
```
# try
helm install kubedoor . --namespace kubedoor --create-namespace --values values-master.yaml --dry-run --debug
# install
helm install kubedoor . --namespace kubedoor --create-namespace --values values-master.yaml
```
3. 访问WebUI：使用K8S节点IP + kubedoor-web的NodePort访问，默认账号密码都是 **`kubedoor`**
4. 告警逻辑说明：`vmalert`从`VictoriaMetrics`读取数据，并进行规则比较后，如果触发了告警就会通知到`alertmanager`，alertmanager收到告警后会路由到`kubedoor-alarm`进行告警通知和入库。即使您的K8S内已经有`alertmanager`也不用担心，KubeDoor的alertmanager会安装在kubedoor命名空间，不会冲突。
- **agent部署:**
1. 配置文件修改: `values-agent.yaml`
    1. **`ws`**：agent和master是同一个K8S：配置为`ws://kubedoor-master.kubedoor`即可，免认证。如果是跨K8S的情况，请配置为您的kubedoor-web外部可访问的地址端口，并按照例子配置认证信息。
    2. **`MSG_TYPE/MSG_TOKEN`**：大部分对该K8S的操作会通过该机器人进行通知。（不同的K8S可以配置不同的群机器人）
    3. **`OSS_URL`**：java服务执行dump、jfr、jstack时会把数据存放到OSS，请填写您的OSS地址。（注意设置允许内网免认证上传）
    4. **`external_labels_key`**：**注意部署到多套K8S时，请保持external_labels_key都相同，并且与kubedoor-master的也相同。**
    5. **`external_labels_value`**：**注意填写您当前K8S已经在`Prometheus/vmagent`中配置的`external_labels`的value，如果您没有配置过请在您的`Prometheus/vmagent`中新增一个。**
    6. **`monit`**：因为你已经有K8S监控了，monit下面的所有`enable`都配置成`false`。
2. 调整你已有的`Prometheus/vmagent`JOB配置（因为您的JOB配置可能与KubeDoor需求的会有不一样，请参考以下配置调整。）配置完成后确保您的有以下指标：
    - container_cpu_usage_seconds_total
    - container_memory_working_set_bytes
    - container_spec_cpu_quota
    - kube_pod_container_info
    - kube_pod_container_resource_limits
    - kube_pod_container_resource_requests
```
  - job_name: 'k8s-node-exporter'
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - action: replace
      source_labels: [__address__]
      regex: '(.*):10250'
      replacement: '${1}:9100'
      target_label: __address__
    - action: replace
      regex: (.*)
      replacement: $1
      source_labels: [__meta_kubernetes_node_name]
      target_label: kubernetes_node

  - job_name: 'k8s-kubelet'
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - target_label: __address__
      replacement: kubernetes.default.svc:443
    - source_labels: [__meta_kubernetes_node_name]
      regex: (.+)
      target_label: __metrics_path__
      replacement: /api/v1/nodes/${1}/proxy/metrics

  - job_name: 'k8s-cadvisor'
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - target_label: __address__
      replacement: kubernetes.default.svc:443
    - source_labels: [__meta_kubernetes_node_name]
      regex: (.+)
      target_label: __metrics_path__
      replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
    metric_relabel_configs:
    - source_labels: [instance]
      separator: ;
      regex: (.+)
      target_label: node
      replacement: $1
      action: replace

  - job_name: 'kube-state-metrics'
    kubernetes_sd_configs:
    - role: service
    relabel_configs:
    - source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
      regex: kube-state-metrics
      replacement: $1
      action: keep

  - job_name: 'k8s-pods-jvm'
    kubernetes_sd_configs:
    - role: pod
    relabel_configs:
    - source_labels: [__meta_kubernetes_namespace]
      regex: kube.*|nacos|apollo
      action: drop
    - source_labels: [__meta_kubernetes_pod_container_init]
      regex: true
      action: drop
      
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_jvm]
      regex: true|True
      action: keep
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_jvmpath]
      action: replace
      target_label: __metrics_path__
      regex: (.+)
    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
      action: replace
      target_label: __address__
      regex: ([^:]+)(?::\d+)?;(\d+)
      replacement: $1:$2

    - source_labels: [__meta_kubernetes_pod_container_name]
      action: replace
      target_label: k8s_app
    - source_labels: [__meta_kubernetes_namespace]
      action: replace
      target_label: k8s_ns
    - source_labels: [__meta_kubernetes_pod_name]
      action: replace
      target_label: k8s_pod
      
    - source_labels: [__meta_kubernetes_pod_container_name]
      action: replace
      target_label: container
    - source_labels: [__meta_kubernetes_namespace]
      action: replace
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      action: replace
      target_label: pod
```

4. 完成配置修改后执行检查与安装：
```
# try
helm install kubedoor . --namespace kubedoor --create-namespace --values values-agent.yaml --dry-run --debug
# install
helm install kubedoor . --namespace kubedoor --create-namespace --values values-agent.yaml
```
5. 访问KubeDoor-Web，点击`agent管理`，找到您部署agent的K8S名称，状态应该是`在线`，先开启自动采集，设置好高峰期时段，再执行采集：输入需要采集的历史数据时长，点击采集，即可采集历史数据并更新高峰时段数据到管控表。
4. 在其它的K8S部署agent。
   ```
   helm install kubedoor-agent . --namespace kubedoor --create-namespace --values values-agent.yaml --set tsdb.external_labels_value=xxxxxx
   ```
