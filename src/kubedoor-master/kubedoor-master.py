import asyncio
import json
import sys
import time
import base64
import aiohttp
from datetime import datetime, timedelta
from aiohttp import web, WSMsgType
from loguru import logger
import utils, prom_real_time_data
from multidict import MultiDict

logger.remove()
logger.add(
    sys.stderr,
    format='<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> [<level>{level}</level>] <level>{message}</level>',
    level='INFO',
)


async def get_authorization_header(username, password):
    credentials = f'{username}:{password}'
    encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')
    return f'Basic {encoded_credentials}'


async def forward_request(request):
    try:
        data = await request.text()

        permission = request.headers.get('X-User-Permission', '')
        if permission == 'read' and not data.strip().lower().startswith('select'):
            return web.Response(status=403)
        if not data.strip().lower().startswith(('select', 'alter', 'insert')):
            return web.Response(status=403)
        data = data.replace('__KUBEDOORDB__', utils.CK_DATABASE)
        logger.info(f'ğŸ“{data}')

        if data.strip().lower().startswith(('alter')):
            utils.ck_alter(data)
            utils.ck_optimize()
            logger.info("SQL: æ•°æ®æ›´æ–°")
            return web.json_response({"msg": "SQL: æ•°æ®æ›´æ–°å®Œæˆ"})
        else:
            TARGET_URL = f'http://{utils.CK_HOST}:{utils.CK_HTTP_PORT}/?add_http_cors_header=1&default_format=JSONCompact'
            headers = {
                'Authorization': await get_authorization_header(utils.CK_USER, utils.CK_PASSWORD),
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
                'Content-Type': 'text/plain',
            }
            async with aiohttp.ClientSession() as session:
                async with session.post(TARGET_URL, data=data, headers=headers) as response:
                    if response.content_type == 'application/json':
                        response_data = await response.json()
                    else:
                        text = await response.text()
                        response_data = {"msg": text}
                    return web.json_response(response_data)
    except Exception as e:
        logger.error(f"Error in forward_request: {e}")
        return web.json_response({"error": str(e)}, status=500)


clients = {}


async def websocket_handler(request):
    env = request.query.get("env")
    ver = request.query.get("ver", "unknown")
    if not env:
        return web.Response(text="ç¼ºå°‘ env å‚æ•°", status=400)
    if env in clients and clients[env]["online"]:
        return web.Response(text="ç›®æ ‡å®¢æˆ·ç«¯å·²åœ¨çº¿", status=409)

    ws = web.WebSocketResponse()
    await ws.prepare(request)

    logger.info(f"å®¢æˆ·ç«¯è¿æ¥æˆåŠŸï¼Œenv={env} ver={ver}")
    if env not in clients:
        # å¦‚æœæ˜¯æ–°å®¢æˆ·ç«¯ï¼Œåˆå§‹åŒ–çŠ¶æ€
        clients[env] = {"ws": ws, "ver": ver, "last_heartbeat": time.time(), "online": True}
        utils.ck_init_agent_status(env)
    else:
        # å¦‚æœæ˜¯é‡è¿å®¢æˆ·ç«¯ï¼Œæ›´æ–° WebSocket å’ŒçŠ¶æ€
        clients[env]["ws"] = ws
        clients[env]["ver"] = ver
        clients[env]["last_heartbeat"] = time.time()
        clients[env]["online"] = True

    try:
        async for msg in ws:
            if msg.type == WSMsgType.TEXT:
                try:
                    data = json.loads(msg.data)
                except json.JSONDecodeError:
                    logger.error(f"æ”¶åˆ°æ— æ³•è§£æçš„æ¶ˆæ¯ï¼š{msg.data}")
                    continue

                if data.get("type") == "heartbeat":
                    # æ›´æ–°å¿ƒè·³æ—¶é—´
                    clients[env]["last_heartbeat"] = time.time()
                    clients[env]["online"] = True
                    # logger.info(f"[å¿ƒè·³]å®¢æˆ·ç«¯ env={env} ver={ver}")
                elif data.get("type") == "admis":
                    request_id = data["request_id"]
                    namespace = data["namespace"]
                    deployment = data["deployment"]
                    logger.info(f"==========å®¢æˆ·ç«¯ env={env} {request_id} {namespace} {deployment}")
                    deploy_res = utils.get_deploy_admis(env, namespace, deployment)
                    await ws.send_json({"type": "admis", "request_id": request_id, "deploy_res": deploy_res})

                elif data.get("type") == "response":
                    # æ”¶åˆ°å®¢æˆ·ç«¯çš„å“åº”ï¼Œå­˜å‚¨åˆ°å®¢æˆ·ç«¯çš„å“åº”é˜Ÿåˆ—ä¸­
                    request_id = data["request_id"]
                    response = data["response"]
                    if "response_queue" in clients[env]:
                        clients[env]["response_queue"][request_id] = response
                    logger.info(f"[å“åº”]å®¢æˆ·ç«¯ env={env}: request_id={request_id}ï¼š{response}")
                else:
                    logger.info(f"æ”¶åˆ°å®¢æˆ·ç«¯æ¶ˆæ¯ï¼š{msg.data}")
            elif msg.type == WSMsgType.ERROR:
                logger.error(f"å®¢æˆ·ç«¯è¿æ¥å‡ºé”™ï¼Œenv={env}")
    except Exception as e:
        logger.error(f"å®¢æˆ·ç«¯è¿æ¥å¼‚å¸¸æ–­å¼€ï¼Œenv={env}ï¼Œé”™è¯¯ï¼š{e}")
    finally:
        # æ ‡è®°å®¢æˆ·ç«¯ä¸ºç¦»çº¿
        if env in clients:
            clients[env]["online"] = False
            logger.info(f"å®¢æˆ·ç«¯è¿æ¥å…³é—­ï¼Œæ ‡è®°ä¸ºç¦»çº¿ï¼Œenv={env}")

    return ws


async def http_handler(request):
    path = request.path
    method = request.method
    query_params = dict(request.query)
    env = query_params.get("env", None)
    try:
        body = await request.json()
    except:
        body = False
    if not env:
        return web.Response(text="ç¼ºå°‘ env å‚æ•°", status=400)

    if env not in clients or not clients[env]["online"]:
        return web.Response(text="ç›®æ ‡å®¢æˆ·ç«¯ä¸åœ¨çº¿", status=404)

    # æ‰©ç¼©å®¹æ¥å£è¦æŸ¥è¯¢èŠ‚ç‚¹cpuä½¿ç”¨ç‡å¹¶ä¼ ç»™agent
    logger.info(path)
    if path == "/api/scale" and query_params.get("add_label") == 'true':
        node_cpu_list = await utils.get_node_cpu_per(query_params.get("env"))
        body[0]['node_cpu_list'] = node_cpu_list

    # å›ºå®šèŠ‚ç‚¹å‡è¡¡æ¨¡å¼ï¼Œå¢åŠ èŠ‚ç‚¹å¾®è°ƒèƒ½åŠ›
    if path == "/api/balance_node":
        source = body.get('source')
        num = body.get('num')
        type = body.get('type')
        logger.info(body)

        # æŸ¥è¯¢æºèŠ‚ç‚¹æ‰€æœ‰deploymentåˆ—è¡¨
        deployment_list = utils.get_node_deployments(source, env)
        top_deployments = utils.get_deployment_from_control_data(deployment_list, num, type, env)
        body['top_deployments'] = top_deployments

    # å‘ç›®æ ‡å®¢æˆ·ç«¯å‘é€æ¶ˆæ¯
    request_id = str(time.time())  # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºå”¯ä¸€è¯·æ±‚ ID
    message = {
        "type": "request",
        "request_id": request_id,
        "method": method,
        "path": path,
        "query": query_params,
        "body": body,
    }
    await clients[env]["ws"].send_json(message)  # ä½¿ç”¨ send_json å‘é€ JSON æ•°æ®
    logger.info(f"[è¯·æ±‚]å®¢æˆ·ç«¯ env={env}: {message}")

    # ç­‰å¾…å®¢æˆ·ç«¯å“åº”
    if "response_queue" not in clients[env]:
        clients[env]["response_queue"] = {}

    try:
        for _ in range(120 * 10):  # ç­‰å¾… 120 ç§’ï¼Œæ£€æŸ¥å“åº”é˜Ÿåˆ—
            if request_id in clients[env]["response_queue"]:
                response = clients[env]["response_queue"].pop(request_id)
                return web.json_response(response)
            await asyncio.sleep(0.1)
    except Exception as e:
        logger.error(f"ç­‰å¾…å®¢æˆ·ç«¯å“åº”æ—¶å‘ç”Ÿé”™è¯¯ï¼Œenv={env}, é”™è¯¯ï¼š{e}")

    return web.Response(text="å®¢æˆ·ç«¯æœªå“åº”", status=504)


async def status_handler(request):
    agent_info = utils.ck_agent_info()
    agents_status = {
        env: {
            "online": data["online"],
            "last_heartbeat": datetime.fromtimestamp(data["last_heartbeat"]).strftime("%Y-%m-%d %H:%M:%S"),
            "ver": data["ver"],
        }
        for env, data in clients.items()
    }
    agents = utils.merge_dicts(agents_status, agent_info)
    return web.json_response({'data': agents})


async def prom_query_handler(request):
    env_value = request.query.get('env')
    namespace_value = request.query.get('ns')
    metrics_data = prom_real_time_data.get_metrics_data(env_value, namespace_value)
    final_data = prom_real_time_data.process_metrics_data(metrics_data)
    return web.json_response({'data': final_data})


async def prom_ns_handler(request):
    env_value = request.query.get('env')
    if not env_value:
        return web.json_response({'message': 'env query parameter is required'}, status=400)
    try:
        namespaces = utils.fetch_prom_namespaces(env_value)
        return web.json_response({'data': namespaces})
    except Exception as e:
        return web.json_response({'message': str(e)}, status=500)


async def prom_env_handler(request):
    try:
        envs = utils.fetch_prom_envs()
        return web.json_response({'data': envs})
    except Exception as e:
        return web.json_response({'message': str(e)}, status=500)


async def heartbeat_check():
    """å®šæœŸæ£€æŸ¥å®¢æˆ·ç«¯çš„å¿ƒè·³çŠ¶æ€"""
    while True:
        for env, data in clients.items():
            if data["online"] and time.time() - data["last_heartbeat"] > 5:
                # æ ‡è®°è¶…æ—¶å®¢æˆ·ç«¯ä¸ºç¦»çº¿
                data["online"] = False
                logger.warning(f"å®¢æˆ·ç«¯ env={env} è¶…æ—¶ï¼Œæ ‡è®°ä¸ºç¦»çº¿")
        await asyncio.sleep(3)


async def cron_peak_data(request):
    param_combinations = utils.ck_agent_collect_info()

    # ä½¿ç”¨ streaming response ç»™å®¢æˆ·ç«¯é€ä¸ªè¿”å›å“åº”
    async def stream_responses():
        for env, peak_hours in param_combinations:
            query_params = MultiDict([("env", env), ("peak_hours", peak_hours)])
            fake_request = request.clone()
            fake_request._rel_url = fake_request._rel_url.update_query(query_params)
            response = await init_peak_data(fake_request)
            # è§£æ JSON å“åº”å¹¶ç¡®ä¿ä¸­æ–‡å­—ç¬¦ä¸è¢«è½¬ä¹‰
            response_json = json.loads(response.body.decode('utf-8'))
            json_str = json.dumps(response_json, ensure_ascii=False)
            # å°† JSON å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚å¯¹è±¡å†è¿”å›
            yield (json_str + '\n').encode('utf-8')

    # è¿”å›æµå¼å“åº”
    return web.Response(
        content_type='application/json',  # è®¾ç½®æ­£ç¡®çš„ content-type
        charset='utf-8',  # å•ç‹¬è®¾ç½®å­—ç¬¦é›†
        body=stream_responses(),  # ä½¿ç”¨ stream_responses æ¥é€ä¸ªè¿”å›æ•°æ®
    )


async def init_peak_data(request):
    """åˆå§‹åŒ–/æ›´æ–°åŸå§‹èµ„æºè¡¨k8s_resourcesï¼Œåˆå§‹åŒ–/æ›´æ–°èµ„æºç®¡æ§è¡¨k8s_res_control"""
    try:
        env_key = utils.PROM_K8S_TAG_KEY
        env_value = request.query.get("env")
        days = int(request.query.get("days", 2))  # ä¸ä¼ åˆ™é‡‡é›†æ˜¨å¤©+ä»Šå¤©
        peak_hours = request.query.get("peak_hours", "10:00:00-11:30:00")
        logger.info(f"ğŸ›å¼€å§‹è·å–{env_value}ï¼Œ{days}å¤©ï¼Œæ¯æ—¥ã€{peak_hours}ã€‘é«˜å³°æœŸæ•°æ®")
        namespace_str = ".*"  # utils.NAMESPACE_LIST.replace(",", "|")
        duration_str, start_time_part, end_time_part = utils.calculate_peak_duration_and_end_time(peak_hours)

        for i in range(0, days):
            # è®¡ç®—ç»“æŸæ—¶é—´å­—ç¬¦ä¸²
            current_date = datetime.now().date()
            start_time_full = datetime.combine(current_date, start_time_part) - timedelta(days=i)
            end_time_full = datetime.combine(current_date, end_time_part) - timedelta(days=i)
            if datetime.now() < end_time_full:
                logger.info(f"ä»Šå¤©çš„é«˜å³°æœŸè¿˜æœªç»“æŸï¼Œè·³è¿‡{current_date}çš„æ•°æ®é‡‡é›†")
                continue
            utils.check_and_delete_day_data(end_time_full, env_value)
            logger.info(f"ğŸš€è·å–{end_time_full}çš„æ•°æ®======")
            k8s_metrics_list = utils.merged_dict(env_key, env_value, namespace_str, duration_str, start_time_full, end_time_full)
            utils.metrics_to_ck(k8s_metrics_list)
        logger.info(f"ğŸš€{env_value}: é«˜å³°æœŸæ•°æ®é‡‡é›†æµç¨‹ç»“æŸ,å¼€å§‹å–æœ€è¿‘10å¤©cpuä½¿ç”¨æœ€é«˜çš„ä¸€å¤©podæ•°æ®, å†™å…¥ç®¡æ§è¡¨")

        # é‡‡é›†å®Œæˆåï¼Œå–æœ€è¿‘10å¤©cpuæ•°æ®æœ€é«˜çš„ä¸€å¤©podï¼Œæ•°æ®å†™å…¥ç®¡æ§è¡¨
        resources = utils.get_list_from_resources(env_value)
        if utils.is_init_or_update(env_value):
            # åˆå§‹åŒ–
            logger.info(f"ğŸŒŠ{env_value}: åˆå§‹åŒ–ç®¡æ§è¡¨======")
            flag = utils.init_control_data(resources)
        else:
            # æ›´æ–°
            logger.info(f"ğŸŒŠ{env_value}: æ›´æ–°ç®¡æ§è¡¨======")
            flag = utils.update_control_data(resources)

        if not flag:
            return web.json_response({"message": f"{env_value}: å†™å…¥ç®¡æ§è¡¨æ‰§è¡Œå¤±è´¥ï¼Œè¯¦æƒ…è§kubedoor-masteræ—¥å¿—"}, status=500)
        return web.json_response({"message": f"{env_value}: æ‰§è¡Œå®Œæˆ"})
    except Exception as e:
        logger.error(f"Error in table: {e}")
        return web.json_response({"message": str(e)}, status=500)


async def start_background_tasks(app):
    """å¯åŠ¨åå°ä»»åŠ¡"""
    app["heartbeat_task"] = asyncio.create_task(heartbeat_check())


async def cleanup_background_tasks(app):
    """æ¸…ç†åå°ä»»åŠ¡"""
    app["heartbeat_task"].cancel()
    await app["heartbeat_task"]


app = web.Application()
app.router.add_get("/ws", websocket_handler)
app.router.add_post('/api/sql', forward_request)
app.router.add_get("/api/agent_status", status_handler)
app.router.add_get("/api/prom_ns", prom_ns_handler)
app.router.add_get("/api/prom_env", prom_env_handler)
app.router.add_get("/api/prom_query", prom_query_handler)
app.router.add_get("/api/init_peak_data", init_peak_data)
app.router.add_get("/api/cron_peak_data", cron_peak_data)
app.router.add_route('*', "/api/{tail:.*}", http_handler)

# åœ¨åº”ç”¨å¯åŠ¨å’Œå…³é—­æ—¶ç®¡ç†åå°ä»»åŠ¡
app.on_startup.append(start_background_tasks)
app.on_cleanup.append(cleanup_background_tasks)

if __name__ == '__main__':
    web.run_app(app, host='0.0.0.0', port=80)
